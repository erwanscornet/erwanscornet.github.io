<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<head>
	<title>Webpage of Erwan Scornet </title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<meta name="author" content="Erwan Scornet" />
	<meta name="description" content="Webpage of Erwan Scornet, assistant professor at Ecole Polytechnique" />
	<meta name="keywords" content="Erwan Scornet, Polytechnique, machine learning, statistique, random forests, forêts aléatoires, arbres" />
	<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="assets/css/main.css" />
	<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
</head>
<body>

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<header id="header" class="alt">
			<!--<span class="logo"><img src="images/logo.svg" alt="" /></span>-->
			<h1>Erwan Scornet, Assistant professor at Ecole Polytechnique </h1>
			<h2>Statistic, Machine Learning </h2>

			<ul class="icons">
				<li>
					

</li>
<li><a href="https://github.com/erwanscornet" class="icon fa-github alt"><span class="label">GitHub</span></a></li>
<li><a href="https://scholar.google.fr/citations?user=6Qt1NFoAAAAJ&hl=fr" class="icon fa-google alt"><span class="label">Google Scholar</span></a></li>
</ul>
</header>

<!-- Nav -->
<nav id="nav">
	<ul>
		<li><a href="#header">Top</a></li>
		<li><a href="#intro" class="active">Bio</a></li>
		<!--<li><a href="#first">News</a></li>-->
		<!--<li><a href="#second">Research</a></li>-->
		<li><a href="#cta">Publications</a></li>
		<li><a href="#footer">Contact</a></li>
	</ul>
</nav>

<!-- Main -->
<div id="main">

	<!-- Introduction -->
	<section id="intro" class="main">
		<div class="spotlight">
			<div class="content">
				<header class="major">
					<h2>Short Bio</h2>
				</header>
				<div align="justify">
				<p>Since september 2016, I am an assistant professor at the Center for Applied Mathematics (CMAP) in Ecole Polytechnique near Paris. My research interests focus on theoretical statistics and Machine Learning with a particular emphasis on nonparametric estimates. I did my PhD thesis on a particular algorithm of Machine Learning called random forests, under the supervision of <a href="http://www.lsta.upmc.fr/biau.html"> G&eacuterard Biau </a> (LSTA - Paris 6) and <a href="http://cbio.ensmp.fr/~jvert/">  Jean-Philipe Vert </a> (Institut Curie). </p>
				</div> <!-- TODO -->
						<!-- <ul class="actions">
							<li><a href="" class="button">Curriculum Vit&aelig; (english)</a></li>
							<li><a href="" class="button">Curriculum Vit&aelig; (français)</a></li>
						</ul> -->
					</div>
					<span class="image"><img src="images/photo3.png" alt="" /></span>
				</div>
			<h2> <a href="pdf/cv_scornet_compressed.pdf">  Curriculum Vitae  </a> </h2>
			</section>

			<!-- First Section -->
			<section id="first" class="main special">
				<header class="major">
				<h2> Graduate Degree "Artificial Intelligence and Advanced Visual Computing" </h2>
				</header>

				<ul>
				A new graduate degree on Artificial Intelligence opened in September 2018 at Ecole Polytechnique.
				The official training website is <a href="https://portail.polytechnique.edu/graduatedegree/master/artificial-intelligence-advanced-visual-computing"> here </a> 
				and additional information on the scientific 
				content can be found <a href="http://www.lix.polytechnique.fr/Labo/Marie-Paule.Cani/MasterAI/doku.php?id=curriculum"> here </a>. 
				A short summary can also be found <a href="MasterAi-ViC-Mar2018.pdf"> here </a> (presentation of March 2019)
			</ul>

			<ul>
				If you are interested, <a href="https://portail.polytechnique.edu/graduatedegree/master/apply"> applications are here</a>. 
			</ul>
			</section>
			
			


			<!-- Third Section -->
			<section id="first" class="main special">
				<header class="major">
				<h2> Awards and distinctions </h2>
				</header>

				<ul>
				<li> Winner of the <a href="http://smai.emath.fr/spip.php?article359"> Jacques Neveu 2016 Prize </a>  for a thesis in the field of probability or statistic. 
				</ul>
			</section>

				<!--<header class="major">
					<h2>News</h2>
				</header>
				<ul class="features">-->
					<!-- <li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>Date</h3>
						<p><a href="#cta">Revised version of our preprint with </a> with <a href="http://math.univ-lille1.fr/~celisse/">Alain Celisse</a>, about stability and generalisation bounds for the Leave-one-Out.</p>
					</li> -->
					<!-- <li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>Date</h3>
						<p><a href="#cta">New preprint</a> with <a href="http://alquier.ensae.net">Pierre Alquier</a>, about xxx.</p>
					</li> -->
					
					<!--<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>December 9, 2017</h3>
						<p>I am running the <a href="http://nips.cc">NIPS 2017</a> workshop <em><a href="nips2017/50shadesbayesian.html">(Almost) 50 shades of Bayesian Learning: PAC-Bayesian trends and insights</a></em>.
						</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>November 8, 2017</h3>
						<p>Our paper with <a href="http://alquier.ensae.net">Pierre Alquier</a> on PAC-Bayesian bounds for hostile data has been accepted for publication in the <a href="http://www.springer.com/computer/ai/journal/10994">Machine Learning Journal</a>!
						</p>
					</li>
					<li>
						<span class="icon major style4 fa-graduation-cap"></span>
						<h3>November 1, 2017</h3>
						<p>Delighted to greet my new colleague and office mate <a href="http://chercheurs.lille.inria.fr/pgermain/">Pascal Germain</a>. Welcome! <a href="https://modal.lille.inria.fr/wikimodal/doku.php">Modal</a> is doubling its PAC-Bayes coverage!</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>October 28, 2017</h3>
						<p>Our paper with <a href="https://sites.google.com/site/sylvainrobbiano/">S. Robbiano</a> on PAC-Bayesian bounds for high-dimensional ranking has been accepted for publication in the <a href="https://www.journals.elsevier.com/journal-of-statistical-planning-and-inference/">Journal of Statistical Planning and Inference</a>!
						</p>
					</li>
					<li>
						<span class="icon major style4 fa-graduation-cap"></span>
						<h3>October 1, 2017</h3>
						<p>My new student Arthur Leroy has started his PhD. Welcome!</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>September 11, 2017</h3>
						<p>Our NIPS workshop <em><a href="nips2017/50shadesbayesian.html">(Almost) 50 shades of Bayesian Learning: PAC-Bayesian trends and insights</a></em> has been accepted by NIPS!
						</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>July 27, 2017</h3>
						<p>New version of our preprint and Python library <a href="https://github.com/bhargavvader/pycobra">pycobra</a> with Bhargav Srinivasa Desikan.
						</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>May 26, 2017</h3>
						<p>Our paper on quasi-Bayesian NMF (with <a href="http://alquier.ensae.net">Pierre Alquier</a>) is now published in <a href="http://www.springer.com/statistics/statistical+theory+and+methods/journal/12004"><em>Mathematical Methods of Statistics</em></a>!
						</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>April 26, 2017</h3>
						<p><a href="#cta">New preprint</a> with Bhargav Srinivasa Desikan on <a href="https://github.com/bhargavvader/pycobra">pycobra</a>, a Python library for ensemble regression analysis and visualisation.</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>April 7, 2017</h3>
						<p><a href="#cta">Revised version of our preprint</a> with Le Li and <a href="http://www.math.univ-angers.fr/~loustau/">Sébastien Loustau</a>, about quasi-Bayesian online clustering.</p>
					</li>
					<li>
						<span class="icon major style2 fa-code-fork"></span>
						<h3>March 27, 2017</h3>
						<p>New Python library released with Bhargav Srinivasa Desikan: <a href="https://github.com/bhargavvader/pycobra">pycobra</a> for ensemble regression analysis and visualisation.
						</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>February 1, 2017</h3>
						<p>Our paper on quasi-Bayesian NMF (with <a href="http://alquier.ensae.net">Pierre Alquier</a>) has been accepted for publication in <a href="http://www.springer.com/statistics/statistical+theory+and+methods/journal/12004"><em>Mathematical Methods of Statistics</em></a>!
						</p>
					</li>
					<li>
						<span class="icon major style4 fa-chevron-up"></span>
						<h3>January 1, 2017</h3>
						<p>I got promoted to a first class researcher (CR1) Inria position!</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>October 23, 2016</h3>
						<p><a href="#cta">New preprint</a> together with <a href="http://alquier.ensae.net">Pierre Alquier</a>, about PAC-Bayesian bounds for hostile data.</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>August 24, 2016</h3>
						<p><a href="#cta">Revised version of our preprint</a> with <a href="http://alquier.ensae.net">Pierre Alquier</a>, about quasi-Bayesian non-negative matrix factorization.</p>
					</li>
					<li>
						<span class="icon major style1 fa-files-o"></span>
						<h3>August 23, 2016</h3>
						<p><a href="#cta">New preprint</a> together with <a href="http://math.univ-lille1.fr/~celisse/">Alain Celisse</a>, about stability and generalisation bounds for the Leave-one-Out.</p>
					</li>
					<li>
						<span class="icon major style4 fa-graduation-cap"></span>
						<h3>August 22, 2016</h3>
						<p>My new student Bhargav Srinivasa Desikan has joined Inria. Welcome!</p>
					</li>
					<li>
						<span class="icon major style6 fa-cloud-upload"></span>
						<h3>July 27, 2016</h3>
						<p>New website!</p>
					</li>-->
					<!-- <li>
						<span class="icon major style1 fa-code"></span>
						<h3>Ipsum consequat</h3>
						<p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p>
					</li>
					<li>
						<span class="icon major style3 fa-copy"></span>
						<h3>Amed sed feugiat</h3>
						<p>Sed lorem amet ipsum dolor et amet nullam consequat a feugiat consequat tempus veroeros sed consequat.</p>
					</li> -->
				</ul>
				<!-- <footer class="major">
					<ul class="actions">
						<li><a href="generic.html" class="button">Learn More</a></li>
					</ul>
				</footer> -->
			</section>

			<!-- Second Section -->
			<section id="second" class="main">
				<!--<header class="major">
					<h2>Research</h2>
				</header>
				<p>My main line of research is in statistical machine learning. I am primarily interested in the design, analysis and implementation of statistical learning methods for high dimensional problems. My interests include (but are not limited to): PAC-Bayesian theory, sparsity and high-dimensional statistics, optimisation theory, statistical learning theory, non-negative matrix factorisation, aggregation of estimators and classifiers, MCMC algorithms, (un)supervised learning, online clustering, concentration inequalities...
				</p>
				<ul class="statistics">
					<li class="style1">
						<span class="icon fa-files-o"></span>
						<strong>11</strong> Research Articles <br> (7 published)
					</li>
					<li class="style3">
						<span class="icon fa-commenting-o"></span>
						<strong>48</strong> Talks since 2010
					</li>
					<li class="style4">
						<span class="icon fa-graduation-cap"></span>
						<strong>10</strong> Students <br> (2 Ph.D.)
					</li>
					<li class="style5">
						<span class="icon fa-building-o"></span>
						<strong>4</strong> Collaborations with companies
					</li>
				</ul>-->
				<h2>Students</h2>
				<ol>
					<li>
						<a href="http://www.cmapx.polytechnique.fr/~jaouad.mourtada/">Jaouad Mourtada</a> (2016-2020) <br>
						Ph.D. student co-supervised with <a href="http://www.cmap.polytechnique.fr/~gaiffas/">Stéphane Gaïffas</a> 
					</li>

					<li>
						<a href="https://nprost.github.io/"> Nicolas Prost </a>  (2018-2019) <br>
						Ph.D. student co-supervised with <a href="http://juliejosse.com/">Julie Josse</a> and
						<a href="http://gael-varoquaux.info/">Gaël Varoquaux </a> 
					</li>

					<li>
						Clément Bénard (2018-) <br>
						Ph.D. student co-supervised with <a href="http://www.lsta.upmc.fr/biau.html">Gérard Biau </a> and
						<a href="https://www.linkedin.com/in/s%C3%A9bastien-da-veiga-80791013a/?originalSubdomain=fr">Sébastien Da Veiga </a> 
					</li>

					<li>
						Ludovic Arnould (2020-) <br>
						Ph.D. student co-supervised with <a href="http://www.lpsm.paris/pageperso/boyer/">Claire Boyer </a>  
					</li>

					<li>
						Bénédicte Colnet (2020-) <br>
						Ph.D. student co-supervised with <a href="http://juliejosse.com/">Julie Josse</a> and
						<a href="http://gael-varoquaux.info/">Gaël Varoquaux </a> 
					</li>
					
				</ol>
					<!-- <footer class="major">
						<ul class="actions">
							<li><a href="generic.html" class="button">Learn More</a></li>
						</ul>
					</footer> -->
				</section>

				<!-- Get Started -->
				<section id="cta" class="main">
					<header class="major">
						<h2>Publications</h2>
						<!-- &bull; <a href="">HALtools</a> -->
					</header>
					<h3>Preprints</h3>
					<ol>
						<li> J. Josse, N. Prost, E. Scornet, G. Varoquaux. <a href="https://arxiv.org/pdf/1902.06931.pdf"> On the consistency of supervised learning with missing values </a>, 2019  </li>
						<li> J. Mourtada, S. Ga&iumlffas, E. Scornet. <a href="https://arxiv.org/abs/1906.10529"> AMF: Aggregated Mondrian Forests for Online Learning </a>, 2019  </li>
						<li> E. Scornet. <a href="https://arxiv.org/abs/2001.04295"> Trees, forests, and impurity-based variable importance </a>, 2020  </li>
						<li> L. Arnould, C. Boyer, E. Scornet. <a href="https://arxiv.org/abs/2010.15690"> Analyzing the tree-layer structure of Deep Forests </a>, 2020  </li>
						<li> C. B&eacute;nard, S. Da Veiga, E. Scornet. <a href="pdf/MDA_Inconsistency.pdf"> MDA for random forests: inconsistency, and a practical
							solution via the Sobol-MDA </a>, 2021. <a href="pdf/MDA_Inconsistency_supplementary.pdf"> Supplementary Material </a>  </li>

					</ol>
					<h3>Accepted/Published papers</h3>
					<ol>
						<li> Scornet, E., Biau, G. and Vert, J.-P. (2015). <a href="pdf/article.pdf">Consistency of random forests,</a> The Annals of Statistics, Vol. 43, pp. 1716-1741
							(<a href="pdf/supplementary_file.pdf">Supplementary materials </a>).
						<li> Scornet, E. (2016). <a href="pdf/article_asymptotics_RF">On the asymptotics of random forests,</a> Journal of Multivariate Analysis, Vol. 146, pp. 72-83.
						<li> Scornet, E. (2016). <a href="pdf/articlekernel.pdf"> Random forests and kernel methods,</a> IEEE Transactions on Information Theory, Vol. 62, pp. 1485-1500.
						<li> Biau, G., Scornet, E. (2016). <a href="pdf/reviewforest.pdf"> A Random Forest Guided Tour,</a> TEST, Vol. 25, pp. 197-227. (<a href="paper/test_rejoinder.pdf"> Discussion </a>) 
						<li> Scornet, E. (2016). <a href="pdf/article_MATAPLI.pdf"> Promenade en for&ecircts al&eacuteatoires,</a> MATAPLI, Vol. 111. 
						<li> E. Bernard, Y. Jiao, E. Scornet, V. Stoven, T. Walter and J.-P. Vert (2017) <a href="http://www.biorxiv.org/content/early/2017/08/01/171298"> Kernel multitask regression for toxicogenetics,</a> Molecular Informatics, Vol. 36. 
						<li> J. Mourtada, S. Ga&iumlffas, E. Scornet, (2017) <a href="pdf/article_mondrian.pdf"> Universal consistency and minimax rates for online Mondrian Forest,</a> NIPS 2017 (<a href="paper/article_mondrian_supplementary.pdf">Supplementary materials </a>). 
						<li> Scornet, E. (2017). <a href="https://www.esaim-proc.org/articles/proc/abs/2017/05/contents/contents.html"> Tuning parameters in random forests,</a> ESAIM Procs, Vol. 60 pp. 144-162.</li>
						<li> R. Duroux, E. Scornet (2018) <a href="https://hal.archives-ouvertes.fr/hal-01287521"> Impact of subsampling and tree depth on random
							forests</a>, ESAIM: Probability and Statistics, Vol. 22, pp. 96-128 </li>
						<li> G. Biau, E. Scornet, J. Welbl, (2018) <a href="https://arxiv.org/abs/1604.07143"> Neural Random Forests </a>, Sankhya A, pp. 1-40  </li>
						<li> J. Mourtada, S. Ga&iumlffas, E. Scornet (2020) <a href="https://arxiv.org/abs/1803.05784"> Minimax optimal rates for Mondrian trees and forests </a>, The Annals of Statistics </li>
						<li> M. Le Morvan, N. Prost, J. Josse, E. Scornet. & G. Varoquaux (2020)  <a href="https://arxiv.org/abs/2002.00658"> Linear predictor on linearly-generated data with missing values: non consistency and solutions </a>, AISTAT </li>
						<!-- pdf/article_aistat_2020.pdf --> 
						<li> M. Le Morvan, J. Josse, T. Moreau, E. Scornet, G. Varoquaux (2020) <a href="https://arxiv.org/abs/2007.01627"> Neumann networks: differential programming for supervised learning with missing values </a>, NeurIPS (oral communication) </li> 
						<li> C. B&eacute;nard, G. Biau, S. Da Veiga, E. Scornet (2020) <a href="https://arxiv.org/abs/1908.06852"> SIRUS: Stable and Interpretable RUle Set for Classification </a>, Electronic Journal of Statistics 2021, Vol. 15, pp. 427-505  </li>
						<li> C. B&eacute;nard, G. Biau, S. Da Veiga, E. Scornet. <a href="https://arxiv.org/abs/2004.14841"> Interpretable Random Forests via Rule Extraction </a>, accepted in AISTAT 2021  </li></ol>
					
						<h3>Academic publications</h3>
					<ol>
						 <li> PhD thesis <a href="pdf/these.pdf"> Learning with random forests</a>, defended on Monday, 30th November, 2015.   </li>
						 <li> HDR manuscript <a href="pdf/HDR_scornet.pdf"> Random forests, interpretability, neural networks and missing values</a>, defended on the 17th December, 2020.   </li>
					</ol>
					<!-- <footer class="major">
						<ul class="actions">
							<li><a href="generic.html" class="button special">Get Started</a></li>
							<li><a href="generic.html" class="button">Learn More</a></li>
						</ul>
					</footer> -->
				</section>


				<section id="cta" class="main">
					<header class="major">
						<h2>Teaching</h2>
						<!-- &bull; <a href="">HALtools</a> -->
					</header>
					
					You can find the slides of my Deep Learning course below
					
					<ol>
						<li>  <a href="teaching/RegularNN.pdf"> Historical Neural Networks </a>
						<li> <a href="teaching/Optimization.pdf"> Optimization </a>
						<li>  <a href="teaching/CNN.pdf"> Convolutional Neural Networks </a>
						<li>  <a href="teaching/RNN.pdf"> Recurrent Neural Networks </a>
						<li>  <a href="teaching/VAE_GAN.pdf"> Generative Modelling </a>
			
					</ol>
					
				
				</section>



				<section id="cta" class="main">
					<header class="major">
						<h2>Talks</h2>
						<!-- &bull; <a href="">HALtools</a> -->
					</header>
					
					
					<ol>
						<li>  <a href="talks/random_forests.pdf"> Random Forests </a>
						<li> <a href="talks/artificial_intelligence.pdf"> General overview of AI </a>			
					</ol>
					
					<!-- <footer class="major">
						<ul class="actions">
							<li><a href="generic.html" class="button special">Get Started</a></li>
							<li><a href="generic.html" class="button">Learn More</a></li>
						</ul>
					</footer> -->
				</section>

				<section id="cta" class="main">
					<header class="major"> Contact </header>
					<ol>
							<li> Email: prenom.nom@po-ly-tech-ni-que.edu (without hyphens).</li>
							<li> Office: 136, Turing Building, Route de Saclay, Palaiseau.</li>
							<li> Phone number: +33 1 77 57 80 80</li>
					</ol>
				</section>
					
			</div>

			<!-- Footer -->
			<footer id="footer">
				
				
					<p class="copyright"><a href="https://en.wikipedia.org/wiki/Creative_Commons_license"><i class="fa fa-creative-commons"></i> BY-SA</a> Benjamin Guedj, 2016--2017. Design: <a href="https://html5up.net">HTML5 UP</a>.
						<br>&#8734;</p>
					</footer>

				</div>

				<!-- Scripts -->
				<script src="assets/js/jquery.min.js"></script>
				<script src="assets/js/jquery.scrollex.min.js"></script>
				<script src="assets/js/jquery.scrolly.min.js"></script>
				<script src="assets/js/skel.min.js"></script>
				<script src="assets/js/util.js"></script>
				<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
				<script src="assets/js/main.js"></script>

				<!-- Google Analytics -->
				<script>
					(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
						(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
						m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
					})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

					ga('create', 'UA-81430854-1', 'auto');
					ga('send', 'pageview');

				</script>

			</body>
			</html>
